{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#sheet 3 question 1:\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', LogisticRegression(max_iter=2000))\n",
        "])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRWd1eQoREPm",
        "outputId": "b486194f-094d-43a2-d802-5b74784630d9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9736842105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sheet 3 Question 2:\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "coef = pipe.named_steps['model'].coef_[0]\n",
        "\n",
        "\n",
        "features = data.feature_names\n",
        "\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': features,\n",
        "    'importance': np.abs(coef)\n",
        "})\n",
        "\n",
        "\n",
        "importance_df = importance_df.sort_values(by='importance', ascending=False)\n",
        "\n",
        "print(importance_df.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2OBGhELROcK",
        "outputId": "a6dbcf51-cc4a-4da8-a36d-0cacecdd2951"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 feature  importance\n",
            "21         worst texture    1.350606\n",
            "10          radius error    1.268178\n",
            "28        worst symmetry    1.208200\n",
            "7    mean concave points    1.119804\n",
            "26       worst concavity    0.943053\n",
            "13            area error    0.907186\n",
            "20          worst radius    0.879840\n",
            "23            worst area    0.841846\n",
            "6         mean concavity    0.801458\n",
            "27  worst concave points    0.778217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB47fT3RK5RS",
        "outputId": "65e7a0ee-c812-4bb6-841c-e70405cb6d7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree\n",
            "Training Accuracy: 1.0\n",
            "Test Accuracy: 0.9473684210526315\n",
            "----------------------------------------\n",
            "Random Forest\n",
            "Training Accuracy: 1.0\n",
            "Test Accuracy: 0.9649122807017544\n",
            "\n",
            "Top 5 Features (Random Forest):\n",
            "                 feature  importance\n",
            "23            worst area    0.153892\n",
            "27  worst concave points    0.144663\n",
            "7    mean concave points    0.106210\n",
            "20          worst radius    0.077987\n",
            "6         mean concavity    0.068001\n",
            "----------------------------------------\n",
            "Gradient Boosting\n",
            "Training Accuracy: 1.0\n",
            "Test Accuracy: 0.956140350877193\n",
            "\n",
            "Top 5 Features (Gradient Boosting):\n",
            "                 feature  importance\n",
            "7    mean concave points    0.450528\n",
            "27  worst concave points    0.240103\n",
            "20          worst radius    0.075589\n",
            "22       worst perimeter    0.051408\n",
            "21         worst texture    0.039886\n",
            "----------------------------------------\n",
            "Model Comparison:\n",
            "Decision Tree Test Accuracy: 0.9473684210526315\n",
            "Random Forest Test Accuracy: 0.9649122807017544\n",
            "Gradient Boosting Test Accuracy: 0.956140350877193\n"
          ]
        }
      ],
      "source": [
        "# Sheet 4 :Question 4\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "\n",
        "data = load_breast_cancer()\n",
        "\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "dt_train_acc = dt.score(X_train, y_train)\n",
        "dt_test_acc = dt.score(X_test, y_test)\n",
        "\n",
        "print(\"Decision Tree\")\n",
        "print(\"Training Accuracy:\", dt_train_acc)\n",
        "print(\"Test Accuracy:\", dt_test_acc)\n",
        "print(\"-\" * 40)\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "rf_train_acc = rf.score(X_train, y_train)\n",
        "rf_test_acc = rf.score(X_test, y_test)\n",
        "\n",
        "print(\"Random Forest\")\n",
        "print(\"Training Accuracy:\", rf_train_acc)\n",
        "print(\"Test Accuracy:\", rf_test_acc)\n",
        "\n",
        "\n",
        "rf_importances = pd.DataFrame({\n",
        "    \"feature\": X.columns,\n",
        "    \"importance\": rf.feature_importances_\n",
        "}).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "print(\"\\nTop 5 Features (Random Forest):\")\n",
        "print(rf_importances.head(5))\n",
        "print(\"-\" * 40)\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "gb.fit(X_train, y_train)\n",
        "\n",
        "gb_train_acc = gb.score(X_train, y_train)\n",
        "gb_test_acc = gb.score(X_test, y_test)\n",
        "\n",
        "print(\"Gradient Boosting\")\n",
        "print(\"Training Accuracy:\", gb_train_acc)\n",
        "print(\"Test Accuracy:\", gb_test_acc)\n",
        "\n",
        "gb_importances = pd.DataFrame({\n",
        "    \"feature\": X.columns,\n",
        "    \"importance\": gb.feature_importances_\n",
        "}).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "print(\"\\nTop 5 Features (Gradient Boosting):\")\n",
        "print(gb_importances.head(5))\n",
        "print(\"-\" * 40)\n",
        "\n",
        "print(\"Model Comparison:\")\n",
        "print(\"Decision Tree Test Accuracy:\", dt_test_acc)\n",
        "print(\"Random Forest Test Accuracy:\", rf_test_acc)\n",
        "print(\"Gradient Boosting Test Accuracy:\", gb_test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sheet 4 Assignment\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "# Task 1: Decision Tree (Full & Pruned)\n",
        "\n",
        "print(\" Task 1: Decision Tree: \")\n",
        "\n",
        "dt_full = DecisionTreeClassifier(random_state=42)\n",
        "dt_full.fit(X_train, y_train)\n",
        "print(\"Full Decision Tree\")\n",
        "print(\"Train Accuracy:\", dt_full.score(X_train, y_train))\n",
        "print(\"Test Accuracy:\", dt_full.score(X_test, y_test))\n",
        "\n",
        "dt_pruned = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "dt_pruned.fit(X_train, y_train)\n",
        "print(\"\\nPruned Decision Tree (max_depth=3)\")\n",
        "print(\"Train Accuracy:\", dt_pruned.score(X_train, y_train))\n",
        "print(\"Test Accuracy:\", dt_pruned.score(X_test, y_test))\n",
        "print(\"-\"*50)\n",
        "\n",
        "# Task 2: Random Forest\n",
        "print(\"Task 2: Random Forest (100 trees) :\")\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "print(\"Train Accuracy:\", rf.score(X_train, y_train))\n",
        "print(\"Test Accuracy:\", rf.score(X_test, y_test))\n",
        "\n",
        "rf_importances = pd.DataFrame({\n",
        "    \"feature\": X.columns,\n",
        "    \"importance\": rf.feature_importances_\n",
        "}).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "print(\"\\nTop 5 Features (Random Forest):\")\n",
        "print(rf_importances.head(5))\n",
        "print(\"-\"*50)\n",
        "\n",
        "# Task 3: Gradient Boosting (default + parameter tuning)\n",
        "print(\" Task 3: Gradient Boosting :\")\n",
        "learning_rates = [0.01, 0.1]\n",
        "n_estimators_list = [50, 100, 200]\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for n_est in n_estimators_list:\n",
        "        gb = GradientBoostingClassifier(\n",
        "            learning_rate=lr,\n",
        "            n_estimators=n_est,\n",
        "            random_state=42\n",
        "        )\n",
        "        gb.fit(X_train, y_train)\n",
        "        train_acc = gb.score(X_train, y_train)\n",
        "        test_acc = gb.score(X_test, y_test)\n",
        "        print(f\"learning_rate={lr}, n_estimators={n_est} -> Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "gb_default = GradientBoostingClassifier(random_state=42)\n",
        "gb_default.fit(X_train, y_train)\n",
        "gb_importances = pd.DataFrame({\n",
        "    \"feature\": X.columns,\n",
        "    \"importance\": gb_default.feature_importances_\n",
        "}).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "print(\"\\nTop 5 Features (Gradient Boosting):\")\n",
        "print(gb_importances.head(5))\n",
        "print(\"-\"*50)\n",
        "\n",
        "# Task 4\n",
        "print(\" Task 4:\")\n",
        "print(\"Decision Tree Full Test Acc:\", dt_full.score(X_test, y_test))\n",
        "print(\"Decision Tree Pruned Test Acc:\", dt_pruned.score(X_test, y_test))\n",
        "print(\"Random Forest Test Acc:\", rf.score(X_test, y_test))\n",
        "print(\"Gradient Boosting (default) Test Acc:\", gb_default.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hku5pXbSOIFD",
        "outputId": "c3f9604a-5690-4718-c0b9-77fa76f649d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Task 1: Decision Tree: \n",
            "Full Decision Tree\n",
            "Train Accuracy: 1.0\n",
            "Test Accuracy: 0.9473684210526315\n",
            "\n",
            "Pruned Decision Tree (max_depth=3)\n",
            "Train Accuracy: 0.978021978021978\n",
            "Test Accuracy: 0.9473684210526315\n",
            "--------------------------------------------------\n",
            "Task 2: Random Forest (100 trees) :\n",
            "Train Accuracy: 1.0\n",
            "Test Accuracy: 0.9649122807017544\n",
            "\n",
            "Top 5 Features (Random Forest):\n",
            "                 feature  importance\n",
            "23            worst area    0.153892\n",
            "27  worst concave points    0.144663\n",
            "7    mean concave points    0.106210\n",
            "20          worst radius    0.077987\n",
            "6         mean concavity    0.068001\n",
            "--------------------------------------------------\n",
            " Task 3: Gradient Boosting :\n",
            "learning_rate=0.01, n_estimators=50 -> Train Acc: 0.9780, Test Acc: 0.9561\n",
            "learning_rate=0.01, n_estimators=100 -> Train Acc: 0.9868, Test Acc: 0.9561\n",
            "learning_rate=0.01, n_estimators=200 -> Train Acc: 0.9934, Test Acc: 0.9561\n",
            "learning_rate=0.1, n_estimators=50 -> Train Acc: 1.0000, Test Acc: 0.9561\n",
            "learning_rate=0.1, n_estimators=100 -> Train Acc: 1.0000, Test Acc: 0.9561\n",
            "learning_rate=0.1, n_estimators=200 -> Train Acc: 1.0000, Test Acc: 0.9561\n",
            "\n",
            "Top 5 Features (Gradient Boosting):\n",
            "                 feature  importance\n",
            "7    mean concave points    0.450528\n",
            "27  worst concave points    0.240103\n",
            "20          worst radius    0.075589\n",
            "22       worst perimeter    0.051408\n",
            "21         worst texture    0.039886\n",
            "--------------------------------------------------\n",
            " Task 4:\n",
            "Decision Tree Full Test Acc: 0.9473684210526315\n",
            "Decision Tree Pruned Test Acc: 0.9473684210526315\n",
            "Random Forest Test Acc: 0.9649122807017544\n",
            "Gradient Boosting (default) Test Acc: 0.956140350877193\n"
          ]
        }
      ]
    }
  ]
}